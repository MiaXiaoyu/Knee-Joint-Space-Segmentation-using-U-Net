{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "files = zipfile.ZipFile('Knee_Joint_Space_Segmentation--main.zip','r')\n",
        "files.extractall(os.getcwd())"
      ],
      "metadata": {
        "id": "B7sPPSqX5eE9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Knee_Joint_Space_Segmentation--main/Test_Y/.ipynb_checkpoints\n",
        "!rm -r /content/Knee_Joint_Space_Segmentation--main/Test_X/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "Ds8QJOO27kQi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages"
      ],
      "metadata": {
        "id": "5MjplUca4QXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zRI8IZPN4GIy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score\n",
        "import shutil\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " create a custom dataset class for knee joint space dataset."
      ],
      "metadata": {
        "id": "MWxJ3sP-4aVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KneeJointSpaceDataset(Dataset):\n",
        "  def __init__(self, image_folder, mask_folder, transform=None):\n",
        "    self.image_folder = image_folder\n",
        "    self.mask_folder = mask_folder\n",
        "    self.transform = transform\n",
        "    self.image_list = os.listdir(image_folder)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.image_list[idx]\n",
        "    img_path = os.path.join(self.image_folder, img_name)\n",
        "    image = Image.open(img_path).convert(\"L\")\n",
        "\n",
        "    if self.mask_folder:\n",
        "        mask_path = os.path.join(self.mask_folder, img_name)\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "    else:\n",
        "        mask = Image.new(\"L\", image.size)\n",
        "\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "        mask = self.transform(mask)\n",
        "\n",
        "    return image, mask\n"
      ],
      "metadata": {
        "id": "nqcVbyTk4U4i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " UNet"
      ],
      "metadata": {
        "id": "iSwDcOH84kpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "      nn.MaxPool2d(2),\n",
        "      DoubleConv(1, 64),\n",
        "      nn.MaxPool2d(2),\n",
        "      DoubleConv(64, 128),\n",
        "      nn.MaxPool2d(2),\n",
        "      DoubleConv(128, 256),\n",
        "      nn.MaxPool2d(2),\n",
        "      DoubleConv(256, 512)\n",
        "    )\n",
        "    self.middle = DoubleConv(512, 1024)\n",
        "    self.decoder = nn.Sequential(\n",
        "      nn.ConvTranspose2d(1024, 512, 2, stride=2),\n",
        "      DoubleConv(512, 512),\n",
        "      nn.ConvTranspose2d(512, 256, 2, stride=2),\n",
        "      DoubleConv(256, 256),\n",
        "      nn.ConvTranspose2d(256, 128, 2, stride=2),\n",
        "      DoubleConv(128, 128),\n",
        "      nn.ConvTranspose2d(128, 64, 2, stride=2),\n",
        "      DoubleConv(64, 64)\n",
        "    )\n",
        "    self.final = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.encoder(x)\n",
        "    x2 = self.middle(x1)\n",
        "    x3 = self.decoder(x2)\n",
        "    return self.final(x3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yUztoj5S4iHM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "lAw-fmmY-8-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97e1d7b-024c-4efb-bf35-565f9e7a63ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet(\n",
            "  (encoder): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (middle): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (1): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (3): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (5): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (7): DoubleConv(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " load the data and create the dataloaders"
      ],
      "metadata": {
        "id": "llP48x2N47s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_img_folder = \"/content/Knee_Joint_Space_Segmentation--main/Train_X\"\n",
        "train_mask_folder = \"/content/Knee_Joint_Space_Segmentation--main/Train_Y\"\n",
        "\n",
        "dataset = KneeJointSpaceDataset(train_img_folder, train_mask_folder, train_transform)\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "2sWbM6Cj47aD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the train_dataset instance\n",
        "train_dataset = KneeJointSpaceDataset(train_img_folder, train_mask_folder, train_transform)\n",
        "\n",
        "# Test if the dataset can be loaded\n",
        "sample_image, sample_mask = train_dataset[0]\n",
        "print(f\"Sample image shape: {sample_image.shape}\")\n",
        "print(f\"Sample mask shape: {sample_mask.shape}\")\n"
      ],
      "metadata": {
        "id": "uME4Pzjm-fpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b45b93-c961-4b22-c3b8-10f9504f96f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample image shape: torch.Size([1, 256, 256])\n",
            "Sample mask shape: torch.Size([1, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " train the modelKneeJointSpaceSegmentation."
      ],
      "metadata": {
        "id": "gYnuYdja6GpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = UNet().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 150\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "\n",
        "  for images, masks in train_loader:\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(images)\n",
        "    loss = criterion(logits, masks)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "B8dWkonN5hjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b47e82-1afb-44f1-ca40-ad2245cb59dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch [1/150], Loss: 1.6646\n",
            "Epoch [2/150], Loss: 0.6265\n",
            "Epoch [3/150], Loss: 0.4755\n",
            "Epoch [4/150], Loss: 0.3070\n",
            "Epoch [5/150], Loss: 0.2899\n",
            "Epoch [6/150], Loss: 0.2514\n",
            "Epoch [7/150], Loss: 0.1947\n",
            "Epoch [8/150], Loss: 0.1584\n",
            "Epoch [9/150], Loss: 0.2434\n",
            "Epoch [10/150], Loss: 0.1990\n",
            "Epoch [11/150], Loss: 0.1624\n",
            "Epoch [12/150], Loss: 0.1490\n",
            "Epoch [13/150], Loss: 0.1418\n",
            "Epoch [14/150], Loss: 0.1421\n",
            "Epoch [15/150], Loss: 0.1444\n",
            "Epoch [16/150], Loss: 0.1392\n",
            "Epoch [17/150], Loss: 0.1351\n",
            "Epoch [18/150], Loss: 0.1305\n",
            "Epoch [19/150], Loss: 0.1274\n",
            "Epoch [20/150], Loss: 0.1308\n",
            "Epoch [21/150], Loss: 0.1278\n",
            "Epoch [22/150], Loss: 0.1251\n",
            "Epoch [23/150], Loss: 0.1256\n",
            "Epoch [24/150], Loss: 0.1253\n",
            "Epoch [25/150], Loss: 0.1250\n",
            "Epoch [26/150], Loss: 0.1231\n",
            "Epoch [27/150], Loss: 0.1220\n",
            "Epoch [28/150], Loss: 0.1220\n",
            "Epoch [29/150], Loss: 0.1222\n",
            "Epoch [30/150], Loss: 0.1211\n",
            "Epoch [31/150], Loss: 0.1210\n",
            "Epoch [32/150], Loss: 0.1211\n",
            "Epoch [33/150], Loss: 0.1174\n",
            "Epoch [34/150], Loss: 0.1160\n",
            "Epoch [35/150], Loss: 0.1140\n",
            "Epoch [36/150], Loss: 0.1120\n",
            "Epoch [37/150], Loss: 0.1126\n",
            "Epoch [38/150], Loss: 0.1162\n",
            "Epoch [39/150], Loss: 0.1135\n",
            "Epoch [40/150], Loss: 0.1108\n",
            "Epoch [41/150], Loss: 0.1106\n",
            "Epoch [42/150], Loss: 0.1119\n",
            "Epoch [43/150], Loss: 0.1132\n",
            "Epoch [44/150], Loss: 0.1107\n",
            "Epoch [45/150], Loss: 0.1087\n",
            "Epoch [46/150], Loss: 0.1072\n",
            "Epoch [47/150], Loss: 0.1080\n",
            "Epoch [48/150], Loss: 0.1068\n",
            "Epoch [49/150], Loss: 0.1070\n",
            "Epoch [50/150], Loss: 0.1039\n",
            "Epoch [51/150], Loss: 0.1030\n",
            "Epoch [52/150], Loss: 0.1025\n",
            "Epoch [53/150], Loss: 0.1000\n",
            "Epoch [54/150], Loss: 0.0996\n",
            "Epoch [55/150], Loss: 0.1006\n",
            "Epoch [56/150], Loss: 0.0988\n",
            "Epoch [57/150], Loss: 0.0957\n",
            "Epoch [58/150], Loss: 0.0927\n",
            "Epoch [59/150], Loss: 0.0915\n",
            "Epoch [60/150], Loss: 0.0897\n",
            "Epoch [61/150], Loss: 0.0948\n",
            "Epoch [62/150], Loss: 0.0935\n",
            "Epoch [63/150], Loss: 0.1116\n",
            "Epoch [64/150], Loss: 0.1022\n",
            "Epoch [65/150], Loss: 0.0947\n",
            "Epoch [66/150], Loss: 0.0923\n",
            "Epoch [67/150], Loss: 0.0906\n",
            "Epoch [68/150], Loss: 0.0903\n",
            "Epoch [69/150], Loss: 0.0870\n",
            "Epoch [70/150], Loss: 0.0869\n",
            "Epoch [71/150], Loss: 0.0866\n",
            "Epoch [72/150], Loss: 0.0876\n",
            "Epoch [73/150], Loss: 0.0872\n",
            "Epoch [74/150], Loss: 0.0876\n",
            "Epoch [75/150], Loss: 0.0860\n",
            "Epoch [76/150], Loss: 0.0856\n",
            "Epoch [77/150], Loss: 0.0893\n",
            "Epoch [78/150], Loss: 0.0856\n",
            "Epoch [79/150], Loss: 0.0852\n",
            "Epoch [80/150], Loss: 0.0870\n",
            "Epoch [81/150], Loss: 0.0855\n",
            "Epoch [82/150], Loss: 0.0865\n",
            "Epoch [83/150], Loss: 0.0848\n",
            "Epoch [84/150], Loss: 0.0847\n",
            "Epoch [85/150], Loss: 0.0850\n",
            "Epoch [86/150], Loss: 0.0859\n",
            "Epoch [87/150], Loss: 0.1200\n",
            "Epoch [88/150], Loss: 0.1626\n",
            "Epoch [89/150], Loss: 0.1118\n",
            "Epoch [90/150], Loss: 0.1001\n",
            "Epoch [91/150], Loss: 0.0966\n",
            "Epoch [92/150], Loss: 0.0938\n",
            "Epoch [93/150], Loss: 0.0921\n",
            "Epoch [94/150], Loss: 0.0898\n",
            "Epoch [95/150], Loss: 0.0894\n",
            "Epoch [96/150], Loss: 0.0890\n",
            "Epoch [97/150], Loss: 0.0887\n",
            "Epoch [98/150], Loss: 0.0882\n",
            "Epoch [99/150], Loss: 0.0898\n",
            "Epoch [100/150], Loss: 0.0877\n",
            "Epoch [101/150], Loss: 0.0852\n",
            "Epoch [102/150], Loss: 0.0859\n",
            "Epoch [103/150], Loss: 0.0862\n",
            "Epoch [104/150], Loss: 0.0863\n",
            "Epoch [105/150], Loss: 0.0852\n",
            "Epoch [106/150], Loss: 0.0844\n",
            "Epoch [107/150], Loss: 0.0828\n",
            "Epoch [108/150], Loss: 0.0815\n",
            "Epoch [109/150], Loss: 0.0817\n",
            "Epoch [110/150], Loss: 0.0791\n",
            "Epoch [111/150], Loss: 0.0826\n",
            "Epoch [112/150], Loss: 0.0815\n",
            "Epoch [113/150], Loss: 0.0804\n",
            "Epoch [114/150], Loss: 0.0783\n",
            "Epoch [115/150], Loss: 0.0763\n",
            "Epoch [116/150], Loss: 0.0756\n",
            "Epoch [117/150], Loss: 0.0719\n",
            "Epoch [118/150], Loss: 0.0740\n",
            "Epoch [119/150], Loss: 0.0710\n",
            "Epoch [120/150], Loss: 0.0691\n",
            "Epoch [121/150], Loss: 0.0615\n",
            "Epoch [122/150], Loss: 0.0586\n",
            "Epoch [123/150], Loss: 0.0531\n",
            "Epoch [124/150], Loss: 0.0542\n",
            "Epoch [125/150], Loss: 0.0548\n",
            "Epoch [126/150], Loss: 0.0489\n",
            "Epoch [127/150], Loss: 0.0481\n",
            "Epoch [129/150], Loss: 0.0424\n",
            "Epoch [130/150], Loss: 0.0407\n",
            "Epoch [131/150], Loss: 0.0411\n",
            "Epoch [132/150], Loss: 0.0413\n",
            "Epoch [133/150], Loss: 0.0400\n",
            "Epoch [134/150], Loss: 0.0398\n",
            "Epoch [135/150], Loss: 0.0391\n",
            "Epoch [136/150], Loss: 0.0383\n",
            "Epoch [137/150], Loss: 0.0386\n",
            "Epoch [138/150], Loss: 0.0372\n",
            "Epoch [139/150], Loss: 0.0360\n",
            "Epoch [140/150], Loss: 0.0358\n",
            "Epoch [141/150], Loss: 0.0347\n",
            "Epoch [142/150], Loss: 0.0337\n",
            "Epoch [143/150], Loss: 0.0322\n",
            "Epoch [144/150], Loss: 0.0325\n",
            "Epoch [145/150], Loss: 0.0327\n",
            "Epoch [146/150], Loss: 0.0320\n",
            "Epoch [147/150], Loss: 0.0311\n",
            "Epoch [148/150], Loss: 0.0312\n",
            "Epoch [149/150], Loss: 0.0326\n",
            "Epoch [150/150], Loss: 0.0299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly select five images from the dataset and put them at Test_X."
      ],
      "metadata": {
        "id": "KHWMV76A6i9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_x_folder = \"Knee_Joint_Space_Segmentation--main/Test_X\"\n",
        "os.makedirs(test_x_folder, exist_ok=True)\n",
        "\n",
        "all_images = os.listdir(train_img_folder)\n",
        "random.shuffle(all_images)\n",
        "\n",
        "for img_name in all_images[:5]:\n",
        "    shutil.move(os.path.join(train_img_folder, img_name), os.path.join(test_x_folder, img_name))\n"
      ],
      "metadata": {
        "id": "bOLjAnYZ6S5J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the model (modelKneeJointSpaceSegmentation) on five random images available at Test_X and Save the predictive masks at Test_Y. "
      ],
      "metadata": {
        "id": "DbVMpLHQ6m5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = KneeJointSpaceDataset(test_x_folder, None, test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "test_y_folder = \"Knee_Joint_Space_Segmentation--main/Test_Y\"\n",
        "os.makedirs(test_y_folder, exist_ok=True)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for idx, (images, _) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    logits = model(images)\n",
        "    preds = torch.sigmoid(logits)\n",
        "    \n",
        "    # Apply a threshold of 0.5\n",
        "    binary_preds = (preds > 0.5).float()\n",
        "    \n",
        "    pred_img = Image.fromarray((binary_preds.squeeze().cpu().numpy() * 255).astype(np.uint8))\n",
        "    img_name = os.listdir(test_x_folder)[idx]\n",
        "    pred_img.save(os.path.join(test_y_folder, img_name))\n",
        "    print(f\"Prediction saved at {os.path.join(test_y_folder, img_name)}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"Knee_Joint_Space_Segmentation--main/modelKneeJointSpaceSegmentation.pth\")\n"
      ],
      "metadata": {
        "id": "AuUz1ycl6nlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94860126-feda-4ce7-da3a-d76e221205a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction saved at Knee_Joint_Space_Segmentation--main/Test_Y/9991313L.png\n",
            "Prediction saved at Knee_Joint_Space_Segmentation--main/Test_Y/9997610L.png\n",
            "Prediction saved at Knee_Joint_Space_Segmentation--main/Test_Y/9985803L.png\n",
            "Prediction saved at Knee_Joint_Space_Segmentation--main/Test_Y/9983798L.png\n",
            "Prediction saved at Knee_Joint_Space_Segmentation--main/Test_Y/9980704L.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IoU"
      ],
      "metadata": {
        "id": "0dAkhKyV6y-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    y_true = y_true.astype(bool)\n",
        "    y_pred = y_pred.astype(bool)\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n",
        "\n",
        "iou_scores = []\n",
        "\n",
        "for img_name in os.listdir(test_x_folder):\n",
        "    true_mask_path = os.path.join(train_mask_folder, img_name)\n",
        "    pred_mask_path = os.path.join(test_y_folder, img_name)\n",
        "\n",
        "    true_mask = np.array(Image.open(true_mask_path).convert(\"1\").resize((256, 256)))\n",
        "    pred_mask = np.array(Image.open(pred_mask_path).convert(\"1\"))\n",
        "\n",
        "    iou = calculate_iou(true_mask, pred_mask)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "print(\"Mean IoU:\", np.mean(iou_scores))\n"
      ],
      "metadata": {
        "id": "StfWvwai6zbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be614748-c031-4160-e515-d14eb9aceb7b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU: 0.7783633386825821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOvrOQLlf3W3"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}